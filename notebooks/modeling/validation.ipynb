{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e864ca60-dc3d-4200-89f4-15bdab14ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio as rs\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from datetime import datetime\n",
    "from sklearn.utils import resample\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../src/')\n",
    "from evaluation import validation as val\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492aafc0-9e09-4e5b-8e8a-13c8a64dd71b",
   "metadata": {},
   "source": [
    "## Sampling Design\n",
    "- type: pixel-based analysis\n",
    "- design: stratified sampling approach by class\n",
    "- total study area (all pixels in the strata): 26 districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9be5289-9712-47e5-b30c-9bae5efdb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_map = rs.open(f'../../tmp/ghana/preds/mosaic/ghana_v27_2024-09-27.tif')\n",
    "total_samples = 100 # when choosing sample count, consider how many will be dropped from buffer zone AND lack of ARD\n",
    "outfile = f'../../data/validation/sampled_points.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9873d78e-8906-4f7b-b59f-b4c147485cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {0: 269113871, 1: 1272342, 2: 138084189, 3: 99051836}\n",
      "Class proportions: {0: 53.03, 1: 0.25, 2: 27.21, 3: 19.52}\n",
      "Total count (pixels): 507522238\n",
      "Creating buffer with ['v08', 'v14', 'v15', 'v19', 'v20', 'v21', 'v22'] batches\n",
      "(1342, 40)\n",
      "(1342, 41)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiPolygon' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sampled_points \u001b[38;5;241m=\u001b[39m \u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_validation_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../tmp/ghana/preds/mosaic/ghana_v27_2024-09-27.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../params.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/plantation_classifier/notebooks/modeling/../../src/evaluation/validation.py:148\u001b[0m, in \u001b[0;36mrun_validation_workflow\u001b[0;34m(raster_file, total_samples, outfile, buffer_distance, params_path)\u001b[0m\n\u001b[1;32m    146\u001b[0m train_surveys \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_load\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mceo_survey\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    147\u001b[0m class_dist, class_prop \u001b[38;5;241m=\u001b[39m calculate_class_distribution(raster_file)\n\u001b[0;32m--> 148\u001b[0m buffer_zone \u001b[38;5;241m=\u001b[39m \u001b[43mbuffer_training_pts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_surveys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m sampled_points \u001b[38;5;241m=\u001b[39m sample_raster_by_class(raster_file, \n\u001b[1;32m    150\u001b[0m                                         total_samples, \n\u001b[1;32m    151\u001b[0m                                         class_prop,\n\u001b[1;32m    152\u001b[0m                                         buffer_zone,\n\u001b[1;32m    153\u001b[0m                                         outfile)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_points\n",
      "File \u001b[0;32m~/github/plantation_classifier/notebooks/modeling/../../src/evaluation/validation.py:71\u001b[0m, in \u001b[0;36mbuffer_training_pts\u001b[0;34m(buffer_dist, train_batches)\u001b[0m\n\u001b[1;32m     69\u001b[0m gdf_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gdf_train\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbuffer(plot_radius \u001b[38;5;241m+\u001b[39m buffer_dist)\n\u001b[1;32m     70\u001b[0m buffer_zone \u001b[38;5;241m=\u001b[39m gdf_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munary_union\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbuffer_zone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     72\u001b[0m buffer_zone \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries([buffer_zone], crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPSG:3857\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto_crs(epsg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4326\u001b[39m)\n\u001b[1;32m     73\u001b[0m buffer_zone\u001b[38;5;241m.\u001b[39mto_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/validation/buffer.shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiPolygon' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "sampled_points = val.run_validation_workflow(f'../../tmp/ghana/preds/mosaic/ghana_v27_2024-09-27.tif', \n",
    "                                             total_samples, \n",
    "                                             outfile,\n",
    "                                             1000,\n",
    "                                            '../../params.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0c9609b3-2f86-4608-9a47-f2a92d3e341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the AOI with 3 different methods\n",
    "# land_use_map.size\t\n",
    "# Very fast, direct access to array size\t\n",
    "# Includes 255 and other invalid values in the count\n",
    "# Getting the total number of pixels\n",
    "\n",
    "# np.bincount()\n",
    "# Efficiently counts only specified valid classes\n",
    "# Limited by minlength, ignores other valid classes\t\n",
    "# If you know exactly which classes to count\n",
    "\n",
    "# Conditional sum()\t\n",
    "# Counts all pixels except 255, flexible\n",
    "# Slower and more memory-intensive for large datasets\n",
    "# When you want to exclude 255 without specifying valid classes\n",
    "\n",
    "counts = np.bincount(land_use_map.flatten(), minlength=4) \n",
    "classes = [0, 1, 2, 3] \n",
    "valid_counts = counts[classes]\n",
    "total_count = valid_counts.sum()\n",
    "lulc_count = sum(land_use_map[land_use_map != 255])\n",
    "\n",
    "print(land_use_map.size)\n",
    "print(total_count)\n",
    "print(lulc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "349e3194-1083-48f8-9371-e074de68a80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 53.02504025449226,\n",
       " 1: 0.250696798038631,\n",
       " 2: 27.207514993658265,\n",
       " 3: 19.516747953810842}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87b7d2f6-63c7-4dba-8a24-4b1d17bc5771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507522238"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bf05c-593a-477d-92f8-276fdad432bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_path = os.path.join(RESULTS_FOLDER, \"model_SI_LULC.pkl\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# load the test features\n",
    "features_test = \n",
    "\n",
    "# Predict the test labels\n",
    "predicted_labels_test = model.predict(features_test)\n",
    "\n",
    "\n",
    "class_labels = np.unique(labels_test)\n",
    "class_names = ['no tree', 'monoculture', 'agroforestry', 'natural']\n",
    "mask = np.in1d(predicted_labels_test, labels_test)  # noqa: NPY201\n",
    "predictions = predicted_labels_test[mask]\n",
    "true_labels = labels_test[mask]\n",
    "\n",
    "# Extract and display metrics\n",
    "f1_scores = metrics.f1_score(true_labels, predictions, labels=class_labels, average=None)\n",
    "avg_f1_score = metrics.f1_score(true_labels, predictions, average=\"weighted\")\n",
    "recall = metrics.recall_score(true_labels, predictions, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(true_labels, predictions, labels=class_labels, average=None)\n",
    "accuracy = metrics.accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(\"Classification accuracy {:.1f}%\".format(100 * accuracy))\n",
    "print(\"Classification F1-score {:.1f}%\".format(100 * avg_f1_score))\n",
    "print()\n",
    "print(\"             Class              =  F1  | Recall | Precision\")\n",
    "print(\"         --------------------------------------------------\")\n",
    "for idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    line_data = (lulctype, f1_scores[idx] * 100, recall[idx] * 100, precision[idx] * 100)\n",
    "    print(\"         * {0:20s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}\".format(*line_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3677f5-f90e-4523-9a13-46df57fbb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "# visual inspo: https://github.com/sentinel-hub/eo-learn/blob/master/examples/land-cover-map/SI_LULC_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af09a9-4c8d-4460-80d3-3fce281fa096",
   "metadata": {},
   "source": [
    "## Other Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b1e08e0-efe8-43c1-92cf-b0a55aeef19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36934</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>5880</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3361</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2629</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Count  Percentage (%)\n",
       "2    36934            76.0\n",
       "255   5880            12.0\n",
       "1     3361             7.0\n",
       "0     2629             5.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c956c39d-1fa0-42e7-8ce4-f941085e0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a comb mosaic\n",
    "def mosaic_tif(tifs_to_mosaic, outpath):\n",
    "\n",
    "    ''''\n",
    "    Takes in a list of raster files and\n",
    "    merges them to form a single tif.\n",
    "\n",
    "    '''\n",
    "    dir = f'../tmp/ghana/preds/mosaic/'\n",
    "    reader_mode = []\n",
    "\n",
    "    for file in tifs_to_mosaic:\n",
    "        src = rs.open(dir+file)\n",
    "        reader_mode.append(src) \n",
    "    print(f'Merging {len(reader_mode)} tifs.')\n",
    "\n",
    "    mosaic, out_transform = merge(reader_mode)\n",
    "    date = datetime.today().strftime('%Y-%m-%d')\n",
    "    outpath = f\"{dir}{outpath}_{date}.tif\"\n",
    "    out_meta = src.meta.copy()  \n",
    "    out_meta.update({'driver': \"GTiff\",\n",
    "                     'dtype': 'uint8',\n",
    "                     'height': mosaic.shape[1],\n",
    "                     'width': mosaic.shape[2],\n",
    "                     'transform': out_transform,\n",
    "                     'compress':'lzw',\n",
    "                     'nodata': 255})\n",
    "\n",
    "    with rs.open(outpath, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    # Ensure to close all files\n",
    "    for src in reader_mode:\n",
    "        src.close()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ba5f3b1-241e-4f8b-a1ca-4e4b93433e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<open DatasetReader name='../tmp/ghana/preds/mosaic/pd_north_v27_2024-08-23.tif' mode='r'>, <open DatasetReader name='../tmp/ghana/preds/mosaic/pd_east_v27_2024-08-23.tif' mode='r'>, <open DatasetReader name='../tmp/ghana/preds/mosaic/pd_west_v27_2024-08-23.tif' mode='r'>]\n",
      "Merging 3 tifs.\n"
     ]
    }
   ],
   "source": [
    "tifs = ['pd_north_v27_2024-08-23.tif',\n",
    "        'pd_east_v27_2024-08-23.tif',\n",
    "        'pd_west_v27_2024-08-23.tif',\n",
    "       ]\n",
    "\n",
    "mosaic_tif(tifs, 'ghana_v27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b5b60-2b45-4265-a81d-84ef82362dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plantations5",
   "language": "python",
   "name": "plantations5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
