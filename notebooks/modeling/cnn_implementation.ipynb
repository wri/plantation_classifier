{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd04e9d-89f5-4b59-b494-a296c326aa38",
   "metadata": {},
   "source": [
    "# TTC Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870c3bc-539f-49a6-bd5a-c66a6ee3ba93",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* adapt to expect xx input band feature stack. currently expects 17 channels\n",
    "* change the final output layer to support multi-class segmentation with a softmax activation function. currently is sigmoid\n",
    "* adjust input patch size. currently expects 512x512\n",
    "* adjust loss function to be categorical cross-entropy (or Dice loss for imbalanced classes). currently is binary cross-entropy. confirm whether to consider weighted loss function.\n",
    "* model deployment - how large of an area?\n",
    "* model validation - necessary?\n",
    "\n",
    "### Updates reflected in `modified_unet.py`\n",
    "* Removed ConvGRU: classification will be done on a single composite images (not monthly time series). No need for RNN/time layers?\n",
    "* Removed SSE and DropBlock: Starting with a simple model. Attention and regularization can be added later if needed. \n",
    "* Switched Binary to Multiclass Output: Instead of \"tree vs no-tree\" model predicts 4 classes.\n",
    "* Simplified U-Net Encoder-Decoder: Clean, readable U-Net blocks: Conv → BatchNorm → ReLU with skip connections.\n",
    "* Modified Input Channels: Original model expected 17 bands (Sentinel only); your model expects 94 bands (Sentinel + Texture + Tree Features).\n",
    "* Adjust the loss function: currently binary cross-entropy, needs to be categorical cross-entropy using the weight argument in torch.nnn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9b887ee-0a82-4fbb-ba3d-742f72c0f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "from utils.logs import get_logger\n",
    "sys.path.append(os.path.abspath('../../src/'))\n",
    "\n",
    "from features import create_xy as create\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98744e4-247a-482f-90b0-2170dca172d8",
   "metadata": {},
   "source": [
    "## Prep training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "add99acd-dae3-4a40-a146-71aac25f4f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 12:45:56,180 — FEATURIZE — INFO — Writing plot IDs to file...\n",
      "2025-05-02 12:45:56,182 — FEATURIZE — INFO — SUMMARY\n",
      "2025-05-02 12:45:56,183 — FEATURIZE — INFO — 242 plots labeled \"unknown\" were dropped.\n",
      "2025-05-02 12:45:56,185 — FEATURIZE — INFO — 118 plots did not have ARD.\n",
      "2025-05-02 12:45:56,189 — FEATURIZE — INFO — Training data batch includes: 976 plots.\n",
      "2025-05-02 12:45:56,192 — FEATURIZE — INFO — 976 plots will be used in training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 976/976 [01:15<00:00, 12.88it/s]\n"
     ]
    }
   ],
   "source": [
    "params_path = '../../params.yaml'\n",
    "with open(params_path) as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "ceo_batch = params[\"data_load\"][\"ceo_survey\"]\n",
    "logger = get_logger(\"FEATURIZE\", log_level=params[\"base\"][\"log_level\"])\n",
    "\n",
    "X, y = create.build_training_sample_CNN(\n",
    "    ceo_batch,\n",
    "    classes=params[\"data_condition\"][\"classes\"],\n",
    "    n_feats=29,\n",
    "    params_path=params_path,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ba5c64e-0b82-47ff-8e49-1ee3afac08ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../params.yaml'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39cf1211-c067-4963-bcb5-25749564d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14, 29)\n"
     ]
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "sample = hkl.load('../../data/train-pytorch/08003.hkl')\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63a798-d48e-4674-975f-5e5ccb382802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plantations5",
   "language": "python",
   "name": "plantations5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
